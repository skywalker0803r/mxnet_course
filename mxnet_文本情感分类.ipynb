{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mxnet_文本情感分类.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/mxnet_course/blob/master/mxnet_%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljuYmgw1Mxx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install d2lzh \n",
        "#!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOQLPdA6M225",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import d2lzh as d2l\n",
        "import mxnet\n",
        "from mxnet import gluon, init, nd\n",
        "from mxnet.contrib import text\n",
        "from mxnet.gluon import data as gdata, loss as gloss, nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MvFoXGZNBqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def corr1d(X, K):\n",
        "    w = K.shape[0]\n",
        "    Y = nd.zeros((X.shape[0] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        Y[i] = (X[i: i + w] * K).sum()\n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07KnFK0oNES8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "c043e7ca-6962-4447-e90a-8f63fe9ed99d"
      },
      "source": [
        "X, K = nd.array([0, 1, 2, 3, 4, 5, 6]), nd.array([1, 2])\n",
        "corr1d(X, K)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[ 2.  5.  8. 11. 14. 17.]\n",
              "<NDArray 6 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONgiN7gaNGiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "3bc8a20b-8c6c-45dc-da45-7dcd1102be7f"
      },
      "source": [
        "def corr1d_multi_in(X, K):\n",
        "    # 首先沿着X和K的第0维（通道维）遍历。然后使用*将结果列表变成add_n函数的位置参数\n",
        "    #（positional argument）来进行相加\n",
        "    return nd.add_n(*[corr1d(x, k) for x, k in zip(X, K)])\n",
        "\n",
        "X = nd.array([[0, 1, 2, 3, 4, 5, 6],\n",
        "              [1, 2, 3, 4, 5, 6, 7],\n",
        "              [2, 3, 4, 5, 6, 7, 8]])\n",
        "K = nd.array([[1, 2], [3, 4], [-1, -3]])\n",
        "corr1d_multi_in(X, K)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[ 2.  8. 14. 20. 26. 32.]\n",
              "<NDArray 6 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDuQ1cjVNMnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fd1ee66c-3baf-4299-8f87-5f72b3ec86a7"
      },
      "source": [
        "batch_size = 64\n",
        "d2l.download_imdb(data_dir='.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ./aclImdb_v1.tar.gz from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lvdz1fAO0Us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = d2l.read_imdb(folder='/content/aclImdb/train'), d2l.read_imdb(folder='/content/aclImdb/test')\n",
        "vocab = d2l.get_vocab_imdb(train_data)\n",
        "train_iter = gdata.DataLoader(gdata.ArrayDataset(\n",
        "    *d2l.preprocess_imdb(train_data, vocab)), batch_size, shuffle=True)\n",
        "test_iter = gdata.DataLoader(gdata.ArrayDataset(\n",
        "    *d2l.preprocess_imdb(test_data, vocab)), batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjA67LfaNZK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextCNN(nn.Block):\n",
        "    def __init__(self, vocab, embed_size, kernel_sizes, num_channels,\n",
        "                 **kwargs):\n",
        "        super(TextCNN, self).__init__(**kwargs)\n",
        "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
        "        # 不参与训练的嵌入层\n",
        "        self.constant_embedding = nn.Embedding(len(vocab), embed_size)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.decoder = nn.Dense(2)\n",
        "        # 时序最大池化层没有权重，所以可以共用一个实例\n",
        "        self.pool = nn.GlobalMaxPool1D()\n",
        "        self.convs = nn.Sequential()  # 创建多个一维卷积层\n",
        "        for c, k in zip(num_channels, kernel_sizes):\n",
        "            self.convs.add(nn.Conv1D(c, k, activation='relu'))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # 将两个形状是(批量大小, 词数, 词向量维度)的嵌入层的输出按词向量连结\n",
        "        embeddings = nd.concat(\n",
        "            self.embedding(inputs), self.constant_embedding(inputs), dim=2)\n",
        "        # 根据Conv1D要求的输入格式，将词向量维，即一维卷积层的通道维，变换到前一维\n",
        "        embeddings = embeddings.transpose((0, 2, 1))\n",
        "        # 对于每个一维卷积层，在时序最大池化后会得到一个形状为(批量大小, 通道大小, 1)的\n",
        "        # NDArray。使用flatten函数去掉最后一维，然后在通道维上连结\n",
        "        encoding = nd.concat(*[nd.flatten(\n",
        "            self.pool(conv(embeddings))) for conv in self.convs], dim=1)\n",
        "        # 应用丢弃法后使用全连接层得到输出\n",
        "        outputs = self.decoder(self.dropout(encoding))\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXLqXiWeNjZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
        "ctx = d2l.try_all_gpus()\n",
        "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)\n",
        "net.initialize(init.Xavier(), ctx=ctx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZYZ7Fh4PXzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7268bd70-b8b1-4c60-f7f7-95d4e0223d6f"
      },
      "source": [
        "glove_embedding = text.embedding.create(\n",
        "    'glove', pretrained_file_name='glove.6B.100d.txt', vocabulary=vocab)\n",
        "net.embedding.weight.set_data(glove_embedding.idx_to_vec)\n",
        "net.constant_embedding.weight.set_data(glove_embedding.idx_to_vec)\n",
        "net.constant_embedding.collect_params().setattr('grad_req', 'null')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/embeddings/glove/glove.6B.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/embeddings/glove/glove.6B.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgVKXht5PaKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "b78ab254-5599-4818-f1a9-e6cb0474425a"
      },
      "source": [
        "lr, num_epochs = 0.001, 5\n",
        "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n",
        "loss = gloss.SoftmaxCrossEntropyLoss()\n",
        "d2l.train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on [gpu(0)]\n",
            "epoch 1, loss 0.5850, train acc 0.720, test acc 0.830, time 18.5 sec\n",
            "epoch 2, loss 0.3597, train acc 0.840, test acc 0.854, time 18.1 sec\n",
            "epoch 3, loss 0.2637, train acc 0.892, test acc 0.857, time 18.1 sec\n",
            "epoch 4, loss 0.1756, train acc 0.933, test acc 0.867, time 18.1 sec\n",
            "epoch 5, loss 0.1118, train acc 0.960, test acc 0.865, time 18.0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWNjs-4HPxFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "178092b5-735b-4f02-f385-c83794dd1bf9"
      },
      "source": [
        "d2l.predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'great'])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADEe39RgTOpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "93b97bfd-a245-40f4-8dfe-33eceb88c916"
      },
      "source": [
        "d2l.predict_sentiment(net, vocab, ['this', 'movie', 'is', 'so', 'bad'])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcvx9ouBSAgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "11f044cc-43b5-43a1-a8d6-02712573d919"
      },
      "source": [
        "d2l.predict_sentiment(net, vocab, ['this','ruby','is','more','beautiful','than','others'])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJa43NlZTUlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}