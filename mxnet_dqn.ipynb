{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNf1Q0ItHgXH72Qf71Wvsjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/mxnet_course/blob/master/mxnet_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3XziQzQ_D3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install mxnet\n",
        "import mxnet as mx\n",
        "import mxnet.ndarray as nd\n",
        "import mxnet.gluon as gluon\n",
        "from mxnet.gluon.loss import L2Loss\n",
        "import numpy as np\n",
        "from mxnet import init\n",
        "import mxnet.gluon.nn as nn\n",
        "import gym\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94aRiYPC_S3c",
        "colab_type": "text"
      },
      "source": [
        "# Hyper params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuWfwuEv_I3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256          \n",
        "LR = 0.001                                                       \n",
        "EPSILON = 0.95                                                \n",
        "GAMMA = 0.99                                                  \n",
        "MEMORY_CAPACITY = 1000\n",
        "l2loss = L2Loss(batch_axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEkrvMbi_fJd",
        "colab_type": "text"
      },
      "source": [
        "# env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpszm-fx_d_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_name = 'CartPole-v1'\n",
        "env = gym.make(env_name)                 \n",
        "action_dim = env.action_space.n                       \n",
        "state_dim = env.observation_space.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKQ8Mgm2_jj9",
        "colab_type": "text"
      },
      "source": [
        "# Q_net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fQyOdTp_h8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_Q_net(net,action_dim):\n",
        "  with net.name_scope():\n",
        "    net.add(nn.Dense(128,activation='relu'))\n",
        "    net.add(nn.Dense(128,activation='relu'))\n",
        "    net.add(nn.Dense(action_dim))\n",
        "  return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADih4snm_vB1",
        "colab_type": "text"
      },
      "source": [
        "# forward test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YMwgzxL_rhI",
        "colab_type": "code",
        "outputId": "573d5d3c-d403-4fcd-a849-cfea29910d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "state = env.reset()\n",
        "state = nd.array([state])\n",
        "print(state)\n",
        "q = build_Q_net(nn.HybridSequential(),action_dim)\n",
        "q.initialize(init=init.Xavier())\n",
        "print(q(state))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[[ 4.1513246e-02  8.0758378e-05 -3.1380486e-02  3.6230646e-02]]\n",
            "<NDArray 1x4 @cpu(0)>\n",
            "\n",
            "[[ 0.00245794 -0.0123826 ]]\n",
            "<NDArray 1x2 @cpu(0)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa6tEjWbAKWQ",
        "colab_type": "text"
      },
      "source": [
        "# copy params test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvM00e-h_8hf",
        "colab_type": "code",
        "outputId": "f459ffe2-c5cb-4015-8526-6a525e06f2c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# q1\n",
        "q1 = build_Q_net(nn.HybridSequential(),action_dim)\n",
        "q1.initialize(init=init.Xavier())\n",
        "\n",
        "# q2\n",
        "q2 = build_Q_net(nn.HybridSequential(),action_dim)\n",
        "q2.initialize(init=init.Xavier())\n",
        "\n",
        "# different\n",
        "print(q1(state))\n",
        "print(q2(state))\n",
        "\n",
        "# copy params\n",
        "q1.save_parameters('temp')\n",
        "q2.load_parameters('temp')\n",
        "\n",
        "# same\n",
        "print(q1(state))\n",
        "print(q2(state))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[[-0.00558521 -0.00032605]]\n",
            "<NDArray 1x2 @cpu(0)>\n",
            "\n",
            "[[ 0.009007   -0.00357642]]\n",
            "<NDArray 1x2 @cpu(0)>\n",
            "\n",
            "[[-0.00558521 -0.00032605]]\n",
            "<NDArray 1x2 @cpu(0)>\n",
            "\n",
            "[[-0.00558521 -0.00032605]]\n",
            "<NDArray 1x2 @cpu(0)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu4ZYqEtBEjn",
        "colab_type": "text"
      },
      "source": [
        "# memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uITeO6HgAUcW",
        "colab_type": "code",
        "outputId": "3fbe0142-dfd0-4028-b027-8b52e186aec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "s = env.reset()\n",
        "r = 1\n",
        "a = 1\n",
        "d = True\n",
        "s_ = env.reset()\n",
        "transition = np.hstack((s,[a,r,d],s_))\n",
        "print(transition)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.01122862  0.03556599 -0.03206905 -0.03025565  1.          1.\n",
            "  1.          0.04707554 -0.04419894 -0.0043778  -0.04124704]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-lL_VC1BgwN",
        "colab_type": "text"
      },
      "source": [
        "# class DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2vEezgxBQ4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(object):\n",
        "  def __init__(self,action_dim):\n",
        "    # eval_net\n",
        "    self.eval_net = build_Q_net(nn.HybridSequential(),action_dim)\n",
        "    self.eval_net.initialize(init=init.Xavier())\n",
        "    \n",
        "    # initialize forward\n",
        "    state = env.reset()\n",
        "    state = nd.array([state])\n",
        "    _ = self.eval_net(state)\n",
        "    \n",
        "    # memory\n",
        "    self.memory_counter = 0\n",
        "    self.memory = np.zeros(shape=(MEMORY_CAPACITY,state_dim*2+3))\n",
        "    \n",
        "    # trainer\n",
        "    self.trainer = gluon.Trainer(self.eval_net.collect_params(),'Adam',{'learning_rate':LR})\n",
        "  \n",
        "  def choose_action(self,state):\n",
        "    # select best action\n",
        "    if np.random.uniform() < EPSILON:\n",
        "      state = nd.array([state])\n",
        "      action_value = self.eval_net(state)\n",
        "      action = nd.argmax(action_value,axis=1).asscalar()\n",
        "      return int(action)\n",
        "    \n",
        "    # select random action\n",
        "    else:\n",
        "      return np.random.randint(0,action_dim)\n",
        "  \n",
        "  def store_transition(self,s,a,r,d,s_):\n",
        "    # add transition to memory\n",
        "    transition = np.hstack((s,[a,r,d],s_))\n",
        "    index = self.memory_counter % MEMORY_CAPACITY\n",
        "    self.memory[index,:] = transition\n",
        "    self.memory_counter += 1\n",
        "  \n",
        "  def learn(self):\n",
        "    # random sample_index\n",
        "    sample_index = np.random.choice(MEMORY_CAPACITY,BATCH_SIZE)\n",
        "    \n",
        "    # from memory sample a mini_batch_data\n",
        "    b_memory = self.memory[sample_index,:]\n",
        "    b_s = nd.array(b_memory[:,:state_dim])\n",
        "    b_a = nd.array(b_memory[:,state_dim:state_dim+1])\n",
        "    b_r = nd.array(b_memory[:,state_dim+1:state_dim+2])\n",
        "    b_d = nd.array(b_memory[:,state_dim+2:state_dim+3])\n",
        "    b_s_= nd.array(b_memory[:,-state_dim:])\n",
        "    \n",
        "    # squeeze\n",
        "    b_a = nd.squeeze(b_a)\n",
        "    b_r = nd.squeeze(b_r)\n",
        "    b_d = nd.squeeze(b_d)\n",
        "    \n",
        "    # caculate gradient\n",
        "    with mx.autograd.record():\n",
        "      # Q_sp\n",
        "      argmax_Q = nd.argmax(self.eval_net(b_s_),axis=1).astype('uint8')\n",
        "      Q_sp = nd.pick(self.eval_net(b_s_),argmax_Q,axis=1) \n",
        "      Q_sp = Q_sp * (nd.ones(BATCH_SIZE) - b_d)\n",
        "      \n",
        "      # Q_s\n",
        "      Q_s = nd.pick(self.eval_net(b_s),b_a,axis=1)\n",
        "      \n",
        "      # caculate loss\n",
        "      loss = nd.mean(l2loss(Q_s,(b_r + GAMMA*Q_sp)))\n",
        "    \n",
        "    # loss backward and trainer step\n",
        "    loss.backward()\n",
        "    self.trainer.step(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ4qMkyHFBCL",
        "colab_type": "code",
        "outputId": "91ede839-8953-4dab-a981-0d58cca02db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "all_rewards = []\n",
        "avg_rewards = []\n",
        "dqn = DQN(action_dim)\n",
        "\n",
        "for episode in range(1000):\n",
        "  # initialize\n",
        "  state = env.reset()\n",
        "  rewards = []\n",
        "  while True:\n",
        "    # interactive\n",
        "    action = dqn.choose_action(state)\n",
        "    state_ ,reward ,done ,info = env.step(action)\n",
        "    # logging\n",
        "    rewards.append(reward) \n",
        "    dqn.store_transition(state,action,reward,done,state_)\n",
        "    # if is time to learn\n",
        "    if dqn.memory_counter > BATCH_SIZE:\n",
        "      dqn.learn()\n",
        "    # if game over\n",
        "    if done:\n",
        "      break\n",
        "    # if game not over\n",
        "    else:\n",
        "      state = state_\n",
        "  \n",
        "  # record this episode total reward \n",
        "  all_rewards.append(np.sum(rewards))\n",
        "  avg_rewards.append(np.mean(all_rewards[-10:]))\n",
        "  \n",
        "  if episode % 10 == 0:\n",
        "    print(episode,avg_rewards[-1])\n",
        "  \n",
        "  if (all_rewards[-1] >= 500)&(avg_rewards[-1] >= 500*0.9):\n",
        "    print(episode,all_rewards[-1],avg_rewards[-1])\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 9.0\n",
            "10 14.1\n",
            "20 21.0\n",
            "30 30.6\n",
            "40 70.7\n",
            "50 103.4\n",
            "60 198.4\n",
            "70 334.3\n",
            "79 500.0 455.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ9zNfy8KmI1",
        "colab_type": "text"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF5O8FCuFD5d",
        "colab_type": "code",
        "outputId": "ebcdae35-e50b-4e4e-8f52-e022af2a0742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "EPSILON = 1\n",
        "all_rewards = []\n",
        "for episode in range(10):\n",
        "  s = env.reset()\n",
        "  rewards = []\n",
        "  while True:\n",
        "    a = dqn.choose_action(s)\n",
        "    s_ ,r ,done ,info = env.step(a)\n",
        "    rewards.append(r) \n",
        "    if done:\n",
        "      break\n",
        "    s = s_ \n",
        "  all_rewards.append(np.sum(rewards))\n",
        "  print(episode,'score',all_rewards[-1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 score 500.0\n",
            "1 score 500.0\n",
            "2 score 500.0\n",
            "3 score 500.0\n",
            "4 score 500.0\n",
            "5 score 500.0\n",
            "6 score 500.0\n",
            "7 score 500.0\n",
            "8 score 500.0\n",
            "9 score 500.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np_OPc0rKopo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}